import { Client, MessageEvent } from '@line/bot-sdk';
import { getUserPermission } from '@company-bot/shared';
import { transcribeAudio } from '../services/whisper';
import { handleAIChat } from '../services/claude';
import { buildRegistrationPrompt, buildPendingApproval } from '../flex/registration';
import { config } from '../config';

const MAX_AUDIO_SIZE = 25 * 1024 * 1024; // 25MB (Whisper limit)

export async function handleAudioMessage(client: Client, event: MessageEvent): Promise<void> {
  if (event.message.type !== 'audio') return;

  const userId = event.source.userId;
  if (!userId) return;

  console.log(`Audio message from userId: ${userId}, messageId: ${event.message.id}`);

  // Check permissions (same pattern as message.ts)
  const perm = await getUserPermission(userId);
  if (!perm) {
    await client.replyMessage(event.replyToken, buildRegistrationPrompt(config.liffId));
    return;
  }

  if (perm.approved === false) {
    await client.replyMessage(event.replyToken, buildPendingApproval());
    return;
  }

  const accessibleCompanies = Object.entries(perm.companies)
    .filter(([, hasAccess]) => hasAccess)
    .map(([name]) => name);

  if (accessibleCompanies.length === 0) {
    await client.replyMessage(event.replyToken, {
      type: 'text',
      text: '‡∏Ñ‡∏∏‡∏ì‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÉ‡∏î‡πÜ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥',
    });
    return;
  }

  // Reply immediately to acknowledge receipt
  await client.replyMessage(event.replyToken, {
    type: 'text',
    text: 'üéôÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á...',
  });

  try {
    // Download audio from LINE
    const stream = await client.getMessageContent(event.message.id);
    const chunks: Buffer[] = [];
    let totalSize = 0;

    for await (const chunk of stream) {
      totalSize += chunk.length;
      if (totalSize > MAX_AUDIO_SIZE) {
        await client.pushMessage(userId, {
          type: 'text',
          text: '‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏à‡∏≥‡∏Å‡∏±‡∏î 25MB) ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á',
        });
        return;
      }
      chunks.push(Buffer.from(chunk));
    }

    const audioBuffer = Buffer.concat(chunks);
    if (audioBuffer.length === 0) {
      await client.pushMessage(userId, {
        type: 'text',
        text: '‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà',
      });
      return;
    }

    // Transcribe with Whisper
    let transcribedText: string;
    try {
      transcribedText = await transcribeAudio(audioBuffer);
    } catch (err: any) {
      console.error('Whisper transcription error:', err.message);
      await client.pushMessage(userId, {
        type: 'text',
        text: '‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏π‡∏î‡∏ä‡∏±‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà',
      });
      return;
    }

    if (!transcribedText.trim()) {
      await client.pushMessage(userId, {
        type: 'text',
        text: '‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà',
      });
      return;
    }

    console.log(`Transcribed text for ${userId}: ${transcribedText}`);

    // Send transcribed text to AI
    const aiResponse = await handleAIChat(userId, transcribedText, accessibleCompanies);

    // Push result back to user
    await client.pushMessage(userId, {
      type: 'text',
      text: `üìù "${transcribedText}"\n\n${aiResponse}`,
    });
  } catch (err: any) {
    console.error('Audio handler error:', err.message);
    await client.pushMessage(userId, {
      type: 'text',
      text: '‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà',
    });
  }
}
